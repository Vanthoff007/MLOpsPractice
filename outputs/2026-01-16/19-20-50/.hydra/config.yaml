data:
  batch_size: 64
  max_length: 512
model:
  name: bert
  model_name: google/bert_uncased_L-2_H-128_A-2
  tokenizer_name: google/bert_uncased_L-2_H-128_A-2
  lr: 1.0e-05
trainer:
  accelerator: gpu
  devices: 1
  max_epochs: 20
  log_every_n_steps: 10
  deterministic: true
  limit_train_batches: 0.25
  limit_val_batches: ${trainer.limit_train_batches}
seed: 42
